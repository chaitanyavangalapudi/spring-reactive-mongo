 #Note : YAML files canâ€™t be loaded via the @PropertySource annotation. 
#So in the case that you need to load values that way, you need to use a properties file.

# Use the argument -Dspring.profiles.active=staging to use the properties for staging 
spring:
  profiles:
    active:
    - Development
---
spring:
  profiles: reactive
    
mongodb:
  uri: mongodb://testuser:passwd@localhost:27017/testdb
  username: ${USERNAME:testuser}
  password: ${PASSWORD:passwd}
  databaseName: testdb
  enableTls: true  
  dbConnectionTimeout: 30000
  cluster:
       hosts:
          - host: "localhost"
            port: 27017       
       type: "STANDALONE"
       connectionMode: "SINGLE"
  sslConfig:
    protocol: "TLS"
    clientKeyStoreFilePath: "/certs/ssl/keystore.jks"
    clientKeyStorePassword: "passwd"
    clientKeyPassword: "passwd"
    caTrustStoreFilePath: "/certs/ssl/truststore.ts"
    caTrustStorePassword: "passwd"     
    
---

#Spring dev tools properties
#Set enabled: false,if you don't want to use livereload
    
server:
    port: 8080

#Properties related to logging framework 
logging:
  level:
    com.eaiggi: TRACE
#file: logging.txt
    
mongodb:
  uri: mongodb://testuser:passwd@localhost:27017/testdb
  username: ${USERNAME:testuser}
  password: ${PASSWORD:passwd}
  databaseName: testdb
  enableTls: true  
  dbConnectionTimeout: 30000
  cluster:
       hosts:
          - host: "localhsot"
            port: 27017       
       type: "STANDALONE"
       connectionMode: "SINGLE"
  sslConfig:
    protocol: "TLS"
    clientKeyStoreFilePath: ${CLIENT_KEYSTORE_PATH:/certs/ssl/keystore.jks}
    clientKeyStorePassword: ${CLIENT_KEYSTORE_PASSWORD:passwd}
    clientKeyPassword: ${CLIENT_KEY_PASSWORD:passwd}
    caTrustStoreFilePath: ${CA_TRUSTSTORE_PATH:/certs/ssl/truststore.ts}
    caTrustStorePassword: ${CA_TRUSTSTORE_PASSWORD:passwd}    

kafka:  
  topicName: testtopic  
  clientAuthRequired: true  
  enable2eEncryption: true
  lingerMs: 1    
  newTopic: newtopic
  messageKey: kafka-integration.key
  cryptoRsaPrivateKeyPath: "/certs/ssl/rsa_privatekey.key"
  cryptoRsaPublicKeyPath: "/certs/ssl/rsa_publickey.key"    

#Spring dev tools properties
#Set enabled: false,if you don't want to use livereload  
spring:
 security:
  user:
    name: testuser
    password: passwd
  profiles: Development
  devtools:
    restart:
      enabled: true
      exclude: 
  jackson:
    default-property-inclusion: non-null        
  cloud:
    stream:  
      dynamicDestinations: "testtopic1"    
      kafka:
        binder:
          brokers: "localhost:9092"  
          autoCreateTopics: true                
          configuration:
              bootstrap-servers: "localhost:9092"
              auto-offset-reset: earliest
              ssl:        
                security-protocol: "SSL"
                keystore-location: /certs/docker.kafka.server.keystore.jks
                key-password: kafkadocker
                keystore-password: kafkadocker
                truststore-location: /certs/docker.kafka.server.truststore.jks
                truststore-password: kafkadocker
        bindings:
           kafkaConsumer:
             consumer:                                       
               autoCommitOffset: true  
               autoCommitOnError: false
               enableDlq: true 
             #  requeue-rejected: true                                          
      bindings:
         kafkaConsumer:
           destination: testtopic
           group: test-group
           contentType: 'application/x-java-object;type=com.eaiggi.api.mongo.model.Person.java'           
           consumer:            
            concurrency: 20
            headerMode: headers    
            max-attempts: 1                                    
         kafkaPublisher:
           destination: testtopic
           contentType: 'application/x-java-object;type=com.eaiggi.api.mongo.model.Person.java'
           producer:            
            headerMode: headers
            errorChannelEnabled: true   
            partitioned: true
            partition-key-expression: headers['partitionKey']
            partition-count: 2                  
              
  kafka:
    bootstrap-servers: "localhost:9092"
#    ssl:        
#        keystore-location: /certs/docker.kafka.server.keystore.jks
#        key-password: kafkadocker
#        keystore-password: kafkadocker
#        truststore-location: /certs/docker.kafka.server.truststore.jks
#        truststore-password: kafkadocker
    client-id: "testApplication"
    properties:
      security.protocol: "SSL"
    consumer:      
      client-id: testConsumer
      auto-offset-reset: earliest
      enable-auto-commit: true
      auto-commit-interval: 100
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer           
    producer:
      client-id: testProducer
      batch-size: 16384
      buffer-memory: 33554432
      retries: 0
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      
management:
  endpoints.web.exposure.include: bindings
  server.port: 8080

